from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI

# project internal imports
from app.node_functions.chains.tools.models.constants import LAST,FIRST,PRODUCT_AGENT_MODEL,PRODUCT_GROUNDING_MODEL
# from app.node_functions.chains.tools.tools import product_rag_tools
from app.node_functions.chains.tools.models.state_graph_models import GroundingAgentResponse


product_rag_prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "You are a helpful AI assistant that answers Insurance agents' questions on Real-Time clause and Benefit lookup. "
            "You have access to a tool that retrieves relevant context from Evidence of coverage and Summary of Benefits documents "
            "Use the tool to find relevant information before answering questions. "
            "Always cite the source and page_num you use in your answers. "
            "If you cannot find the answer in the retrieved documentation, say so."
        ),
        MessagesPlaceholder(variable_name="product_rag_messages"),
    ]
)

# product_rag_llm = ChatOpenAI(model=PRODUCT_AGENT_MODEL, temperature=0).bind_tools(product_rag_tools)
# product_rag_chain = product_rag_prompt | product_rag_llm

product_grounding_prompt = ChatPromptTemplate.from_messages(
    [
        ("""
    You are a verification model responsible for preventing hallucinations in a RAG system.

    You will be given:
    1. A user question
    2. Retrieved context passages
    3. A candidate answer generated by another model

    Your task:
    - Determine whether the candidate answer is fully supported by the provided context.
    - If the answer contains any information that is not explicitly supported by the context, mark it as NOT GROUNDED.
    - If the answer is grounded, return it unchanged.
    - If the answer is not grounded, rewrite a corrected answer using ONLY the information found in the context. If the context does not contain enough information, respond with: "The context does not provide enough information to answer this question. PLease call Helpdesk"

    Rules:
    - Do NOT add new facts.
    - Do NOT guess or infer beyond what is explicitly stated.
    - Do NOT rely on prior knowledge.
    - Only use the provided context.

    Here is the information:

    [QUESTION] 
    {question} 

    [CONTEXT] 
    {context} 

    [ANSWER] 
    {answer}

    Output format (JSON):
    {{
      "is_grounded": true/false,
      "final_answer": "your grounded answer here"
    }}
    """),
        # MessagesPlaceholder(variable_name="product_grounding_messages"),
    ]
)
# product_grounding_llm = ChatOpenAI(model=PRODUCT_GROUNDING_MODEL, temperature=0)
product_grounding_llm = ChatOpenAI(model=PRODUCT_GROUNDING_MODEL, temperature=0).with_structured_output(GroundingAgentResponse)
product_grounding_chain = (
        {
            "question": lambda x: x["question"],
            "context": lambda x: x["context"],
            "answer": lambda x: x["answer"]
        }
        | product_grounding_prompt
        | product_grounding_llm
)
